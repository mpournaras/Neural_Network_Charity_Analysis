{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff2f27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education</th>\n",
       "      <th>Default_Credit</th>\n",
       "      <th>Housing_Loan</th>\n",
       "      <th>Personal_Loan</th>\n",
       "      <th>Subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>other</td>\n",
       "      <td>married</td>\n",
       "      <td>Primary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>Secondary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>Primary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>Secondary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>Professional_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age       Job Marital_Status               Education Default_Credit  \\\n",
       "0   56     other        married       Primary_Education             no   \n",
       "1   37  services        married     Secondary_Education             no   \n",
       "2   40     admin        married       Primary_Education             no   \n",
       "3   56  services        married     Secondary_Education             no   \n",
       "4   59     admin        married  Professional_Education             no   \n",
       "\n",
       "  Housing_Loan Personal_Loan Subscribed  \n",
       "0           no            no         no  \n",
       "1          yes            no         no  \n",
       "2           no            no         no  \n",
       "3           no           yes         no  \n",
       "4           no            no         no  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import our input dataset\n",
    "tele_df = pd.read_csv('./resources/bank_telemarketing.csv')\n",
    "tele_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22772611",
   "metadata": {},
   "source": [
    "SVMs are a type of binary classifier that use geometric boundaries to distinguish data points from two separate groups. More specifically, SVMs try to calculate a geometric hyperplane that maximizes the distance between the closest data point of both groups:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Unlike logistic regression, which excels in classifying data that is linearly separable but fails in nonlinear relationships, SVMs can build adequate models with linear or nonlinear data. Due to SVMs' ability to create multidimensional borders, SVMs lose their interpretability and behave more like the black box machine learning models, such as basic neural networks and deep learning models.\n",
    "\n",
    "SVMs, like neural networks, can analyze and interpret multiple data types, such as images, natural language voice and text, or tabular data. SVMs perform one task and one task very well—they classify and create regression using two groups. In contrast, neural networks and deep learning models are capable of producing many outputs, which means neural network models can be used to classify multiple groups within the same model. Over the years, techniques have been developed to create multiple SVM models side-by-side for multiple classification problems, such as creating multiple SVM kernels. However, a single SVM is not capable of the same outputs as a single neural network.\n",
    "\n",
    "If we only compare binary classification problems, SVMs have an advantage over neural network and deep learning models:\n",
    "\n",
    "- Neural networks and deep learning models will often converge on a local minimum. In other words, these models will often focus on a specific trend in the data and could miss the \"bigger picture.\"\n",
    "- SVMs are less prone to overfitting because they are trying to maximize the distance, rather than encompass all data within a boundary.\n",
    "\n",
    "Despite these advantages, SVMs are limited in their potential and can still miss critical features and high-dimensionality relationships that a well-trained deep learning model could find. However, in many straightforward binary classification problems, SVMs will outperform the basic neural network, and even deep learning models with ease.\n",
    "\n",
    "To compare and contrast the performance of an SVM versus deep learning model, we'll try to build a binary classifier using the same input data. This adapted real-world dataset (Links to an external site.) contains bank telemarketing metrics that can be used to predict whether or not a customer is likely to subscribe to a banking service after being targeted by telemarketing advertisements. From this dataset, we want to build a binary classifier using an SVM and deep learning model and compare the predictive accuracy of either model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ab907",
   "metadata": {},
   "source": [
    "Unlike neural networks and deep learning models, SVMs can handle unprocessed and processed tabular data. Regardless, we'll preprocesses the dataset and use the preprocessed data for training both models—this ensures a fair comparison. For our first preprocessing workflow, let's encode our categorical variables using Scikit-Learn's *OneHotEncoder* class.\n",
    "\n",
    "First, we must make sure that none of our categorical variables require bucketing. To check this, let's get the column names of categorical variables and check their number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dacbb8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job               9\n",
       "Marital_Status    3\n",
       "Education         4\n",
       "Default_Credit    2\n",
       "Housing_Loan      2\n",
       "Personal_Loan     2\n",
       "Subscribed        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "tele_cat = tele_df.dtypes[tele_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "tele_df[tele_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a6070",
   "metadata": {},
   "source": [
    "Looking at the number of unique values for each categorical variable, there were no categories that require bucketing prior to encoding. Therefore, we're ready to encode..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51edb3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\anaconda3\\envs\\mlenv3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_admin</th>\n",
       "      <th>Job_blue-collar</th>\n",
       "      <th>Job_entrepreneur</th>\n",
       "      <th>Job_management</th>\n",
       "      <th>Job_other</th>\n",
       "      <th>Job_retired</th>\n",
       "      <th>Job_self-employed</th>\n",
       "      <th>Job_services</th>\n",
       "      <th>Job_technician</th>\n",
       "      <th>Marital_Status_divorced</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_Secondary_Education</th>\n",
       "      <th>Education_Tertiary_Education</th>\n",
       "      <th>Default_Credit_no</th>\n",
       "      <th>Default_Credit_yes</th>\n",
       "      <th>Housing_Loan_no</th>\n",
       "      <th>Housing_Loan_yes</th>\n",
       "      <th>Personal_Loan_no</th>\n",
       "      <th>Personal_Loan_yes</th>\n",
       "      <th>Subscribed_no</th>\n",
       "      <th>Subscribed_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Job_admin  Job_blue-collar  Job_entrepreneur  Job_management  Job_other  \\\n",
       "0        0.0              0.0               0.0             0.0        1.0   \n",
       "1        0.0              0.0               0.0             0.0        0.0   \n",
       "2        1.0              0.0               0.0             0.0        0.0   \n",
       "3        0.0              0.0               0.0             0.0        0.0   \n",
       "4        1.0              0.0               0.0             0.0        0.0   \n",
       "\n",
       "   Job_retired  Job_self-employed  Job_services  Job_technician  \\\n",
       "0          0.0                0.0           0.0             0.0   \n",
       "1          0.0                0.0           1.0             0.0   \n",
       "2          0.0                0.0           0.0             0.0   \n",
       "3          0.0                0.0           1.0             0.0   \n",
       "4          0.0                0.0           0.0             0.0   \n",
       "\n",
       "   Marital_Status_divorced  ...  Education_Secondary_Education  \\\n",
       "0                      0.0  ...                            0.0   \n",
       "1                      0.0  ...                            1.0   \n",
       "2                      0.0  ...                            0.0   \n",
       "3                      0.0  ...                            1.0   \n",
       "4                      0.0  ...                            0.0   \n",
       "\n",
       "   Education_Tertiary_Education  Default_Credit_no  Default_Credit_yes  \\\n",
       "0                           0.0                1.0                 0.0   \n",
       "1                           0.0                1.0                 0.0   \n",
       "2                           0.0                1.0                 0.0   \n",
       "3                           0.0                1.0                 0.0   \n",
       "4                           0.0                1.0                 0.0   \n",
       "\n",
       "   Housing_Loan_no  Housing_Loan_yes  Personal_Loan_no  Personal_Loan_yes  \\\n",
       "0              1.0               0.0               1.0                0.0   \n",
       "1              0.0               1.0               1.0                0.0   \n",
       "2              1.0               0.0               1.0                0.0   \n",
       "3              1.0               0.0               0.0                1.0   \n",
       "4              1.0               0.0               1.0                0.0   \n",
       "\n",
       "   Subscribed_no  Subscribed_yes  \n",
       "0            1.0             0.0  \n",
       "1            1.0             0.0  \n",
       "2            1.0             0.0  \n",
       "3            1.0             0.0  \n",
       "4            1.0             0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(tele_df[tele_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(tele_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2798ad",
   "metadata": {},
   "source": [
    "Once we have our encoded categorical variables, we need to merge our encoded columns back into our original DataFrame (as well as remove the unencoded columns). To replace the unencoded categorical variables with the encoded variables, add and run the following code to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9c38a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\AppData\\Local\\Temp\\ipykernel_20764\\2291554867.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  tele_df = tele_df.drop(tele_cat,1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job_admin</th>\n",
       "      <th>Job_blue-collar</th>\n",
       "      <th>Job_entrepreneur</th>\n",
       "      <th>Job_management</th>\n",
       "      <th>Job_other</th>\n",
       "      <th>Job_retired</th>\n",
       "      <th>Job_self-employed</th>\n",
       "      <th>Job_services</th>\n",
       "      <th>Job_technician</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_Secondary_Education</th>\n",
       "      <th>Education_Tertiary_Education</th>\n",
       "      <th>Default_Credit_no</th>\n",
       "      <th>Default_Credit_yes</th>\n",
       "      <th>Housing_Loan_no</th>\n",
       "      <th>Housing_Loan_yes</th>\n",
       "      <th>Personal_Loan_no</th>\n",
       "      <th>Personal_Loan_yes</th>\n",
       "      <th>Subscribed_no</th>\n",
       "      <th>Subscribed_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Job_admin  Job_blue-collar  Job_entrepreneur  Job_management  \\\n",
       "0   56        0.0              0.0               0.0             0.0   \n",
       "1   37        0.0              0.0               0.0             0.0   \n",
       "2   40        1.0              0.0               0.0             0.0   \n",
       "3   56        0.0              0.0               0.0             0.0   \n",
       "4   59        1.0              0.0               0.0             0.0   \n",
       "\n",
       "   Job_other  Job_retired  Job_self-employed  Job_services  Job_technician  \\\n",
       "0        1.0          0.0                0.0           0.0             0.0   \n",
       "1        0.0          0.0                0.0           1.0             0.0   \n",
       "2        0.0          0.0                0.0           0.0             0.0   \n",
       "3        0.0          0.0                0.0           1.0             0.0   \n",
       "4        0.0          0.0                0.0           0.0             0.0   \n",
       "\n",
       "   ...  Education_Secondary_Education  Education_Tertiary_Education  \\\n",
       "0  ...                            0.0                           0.0   \n",
       "1  ...                            1.0                           0.0   \n",
       "2  ...                            0.0                           0.0   \n",
       "3  ...                            1.0                           0.0   \n",
       "4  ...                            0.0                           0.0   \n",
       "\n",
       "   Default_Credit_no  Default_Credit_yes  Housing_Loan_no  Housing_Loan_yes  \\\n",
       "0                1.0                 0.0              1.0               0.0   \n",
       "1                1.0                 0.0              0.0               1.0   \n",
       "2                1.0                 0.0              1.0               0.0   \n",
       "3                1.0                 0.0              1.0               0.0   \n",
       "4                1.0                 0.0              1.0               0.0   \n",
       "\n",
       "   Personal_Loan_no  Personal_Loan_yes  Subscribed_no  Subscribed_yes  \n",
       "0               1.0                0.0            1.0             0.0  \n",
       "1               1.0                0.0            1.0             0.0  \n",
       "2               1.0                0.0            1.0             0.0  \n",
       "3               0.0                1.0            1.0             0.0  \n",
       "4               1.0                0.0            1.0             0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "tele_df = tele_df.merge(encode_df,left_index=True, right_index=True)\n",
    "tele_df = tele_df.drop(tele_cat,1)\n",
    "tele_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7702110",
   "metadata": {},
   "source": [
    "Now, we must split our data into the training and testing sets prior to standardization to not incorporate the testing values into the scale—testing values are only for evaluation. To perform the training/test split and standardize our numerical variables, add and run the following code in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f79efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove loan status target from features data\n",
    "y = tele_df.Subscribed_yes.values\n",
    "X = tele_df.drop(columns=[\"Subscribed_no\",\"Subscribed_yes\"]).values\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c180b7",
   "metadata": {},
   "source": [
    "After standardizing variables in both the training and testing data, our dataset is ready for both models. First, we'll train and evaluate our SVM.\n",
    "\n",
    "REWIND\n",
    "SVMs can be built using Scikit-learn's **SVCclass** in the **svm** module.\n",
    "\n",
    "For our purposes, we'll use the SVM's **linear** kernel to try and create a linear boundary between the \"Subscribed_yes\" versus \"Subscribed_no\" groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b7c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVM model\n",
    "svm = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd1e6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9078a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM model accuracy: 0.873\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "print(f\" SVM model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb1a64",
   "metadata": {},
   "source": [
    "Looking at the output of our SVM model, the model was able to correctly predict the customers who subscribed roughly 87% of the time, which is a respectable first-pass model. Next, we need to compile and evaluate our deep learning model. Again, we'll use our typical binary classifier parameters:\n",
    "\n",
    "- Our first hidden layer will have an **input_dim** equal to the length of the scaled feature data X , 10 neuron **units**, and will use the **relu** activation function.\n",
    "- Our second hidden layer will have 5 neuron **units** and also will use the **relu** activation function.\n",
    "- The loss function should be **binary_crossentropy**, using the **adam** optimizer.\n",
    "\n",
    "NOTE\n",
    "Unlike our basic neural network model, we don't want to use two to three times the number of neurons as input variables—we don't want our deeper layers to overfit the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb01cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 10\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de504f05",
   "metadata": {},
   "source": [
    "Lastly, we need to train and evaluate our deep learning model. Because this dataset contains fewer features than other datasets we have used previously, we only need to train over a maximum of 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2702132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.4658 - accuracy: 0.8215\n",
      "Epoch 2/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3743 - accuracy: 0.8735\n",
      "Epoch 3/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3700 - accuracy: 0.8735\n",
      "Epoch 4/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3684 - accuracy: 0.8734\n",
      "Epoch 5/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8734\n",
      "Epoch 6/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3662 - accuracy: 0.8735\n",
      "Epoch 7/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3655 - accuracy: 0.8733\n",
      "Epoch 8/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8733\n",
      "Epoch 9/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8731\n",
      "Epoch 10/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3638 - accuracy: 0.8736\n",
      "Epoch 11/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8736\n",
      "Epoch 12/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8733\n",
      "Epoch 13/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8733\n",
      "Epoch 14/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8731\n",
      "Epoch 15/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8735\n",
      "Epoch 16/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8736\n",
      "Epoch 17/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8733\n",
      "Epoch 18/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8733\n",
      "Epoch 19/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8733\n",
      "Epoch 20/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8732\n",
      "Epoch 21/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8733\n",
      "Epoch 22/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8736\n",
      "Epoch 23/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8737\n",
      "Epoch 24/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8738\n",
      "Epoch 25/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8731\n",
      "Epoch 26/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8739\n",
      "Epoch 27/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8738\n",
      "Epoch 28/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8734\n",
      "Epoch 29/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8735\n",
      "Epoch 30/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8741\n",
      "Epoch 31/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3616 - accuracy: 0.8739\n",
      "Epoch 32/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8735\n",
      "Epoch 33/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8735\n",
      "Epoch 34/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8737\n",
      "Epoch 35/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8736\n",
      "Epoch 36/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8735\n",
      "Epoch 37/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8738\n",
      "Epoch 38/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8739\n",
      "Epoch 39/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8737\n",
      "Epoch 40/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8736\n",
      "Epoch 41/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8740\n",
      "Epoch 42/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8741\n",
      "Epoch 43/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8738\n",
      "Epoch 44/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8737\n",
      "Epoch 45/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8741\n",
      "Epoch 46/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8738\n",
      "Epoch 47/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8736\n",
      "Epoch 48/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8736\n",
      "Epoch 49/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8735\n",
      "Epoch 50/50\n",
      "715/715 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8740\n",
      "239/239 - 0s - loss: 0.3690 - accuracy: 0.8734 - 371ms/epoch - 2ms/step\n",
      "Loss: 0.36895403265953064, Accuracy: 0.8733595609664917\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50) \n",
    "# Evaluate the model using the test data \n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de78d2c",
   "metadata": {},
   "source": [
    "Looking at the results of our comparative analysis, the SVM and deep learning models both achieved a predictive accuracy around 87%. Additionally, both models take similar amounts of time to train on the input data. The only noticeable difference between the two models is implementation—the amount of code required to build and train the SVM is notably less than the comparable deep learning model. As a result, many data scientists will prefer to use SVMs by default, then turn to deep learning models, as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725b4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv3",
   "language": "python",
   "name": "mlenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
